# Notes on Machine Unlearning

[Sort by topic](readme_topic.md).

## 2021

Brophy and Lowd. [Machine Unlearning for Random Forests](https://arxiv.org/abs/2009.05567). In ICML 2021.

Bourtoule et al. [Machine Unlearning](https://arxiv.org/abs/1912.03817). In IEEE Symposium on Security and Privacy 2021.

Huang et al. [Unlearnable Examples: Making Personal Data Unexploitable](https://arxiv.org/abs/2101.04898). In ICLR 2021.

Neel et al. [Descent-to-Delete:
Gradient-Based Methods for Machine Unlearning](http://proceedings.mlr.press/v132/neel21a.html). In ALT 2021.

Schelter et al. [HedgeCut: Maintaining Randomised Trees for Low-Latency Machine Unlearning](https://ssc.io/pdf/rdm235.pdf). In SIGMOD 2021.

Chen et al. [Graph Unlearning](https://arxiv.org/abs/2103.14991). In arXiv 2021.

Fu et al. [Bayesian Inference Forgetting](https://arxiv.org/abs/2101.06417). In arXiv 2021.

Gupta et al. [Adaptive Machine Unlearning](https://arxiv.org/pdf/2106.04378.pdf). In arXiv 2021.

He et al. [DeepObliviate: A Powerful Charm for Erasing Data Residual Memory in Deep Neural Networks](https://arxiv.org/abs/2105.06209). In arXiv 2021.

Khan and Swaroop. [Knowledge-Adaptation Priors](https://arxiv.org/abs/2106.08769). In arXiv 2021.

Sekhari et al. [Remember What You Want to Forget: Algorithms for Machine Unlearning](https://arxiv.org/abs/2103.03279). In arXiv 2021.

Ullah et al. [Machine Unlearning via Algorithmic Stability](https://arxiv.org/abs/2102.13179). In arXiv 2021.

Warnecke et al. [Machine Unlearning for Features and Labels](https://arxiv.org/pdf/2108.11577.pdf). In arXiv 2021.

## 2020

Guo et al. [Certified Data Removal from Machine Learning Models](https://arxiv.org/abs/1911.03030). In ICML 2020.

Golatkar et al. [Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks](https://arxiv.org/abs/1911.04933). In CVPR 2020.

Wu et. al [DeltaGrad: Rapid Retraining of Machine Learning Models](https://icml.cc/virtual/2020/poster/5915). In ICML 2020.

Aldaghri et al. [Coded Machine Unlearning](https://arxiv.org/abs/2012.15721). In arXiv 2020.

Baumhauer et al. [Machine Unlearning: Linear Filtration for Logit-based Classifiers](https://arxiv.org/abs/2002.02730). In arXiv 2020.

Garg et al. [Formalizing Data Deletion in the Context of the Right to be Forgotten](https://arxiv.org/abs/2002.10635). In arXiv 2020.

Chen et al. [When Machine Unlearning Jeopardizes Privacy](https://arxiv.org/abs/2005.02205). In arXiv 2020.

Felps et al. [Class Clown: Data Redaction in Machine Unlearning at Enterprise Scale](https://arxiv.org/abs/2012.04699). In arXiv 2020.

Golatkar et al. [Mixed-Privacy Forgetting in Deep Networks](https://arxiv.org/abs/2012.13431). In arXiv 2020.

Golatkar et al. [Forgetting Outside the Box: Scrubbing Deep Networks of Information Accessible from Input-Output Observations](https://arxiv.org/abs/1911.04933). In arXiv 2020.

Izzo et al. [Approximate Data Deletion from Machine Learning Models: Algorithms and Evaluations](https://arxiv.org/abs/2002.10077). In arXiv 2020.

Liu et al. [Learn to Forget: User-Level Memorization
Elimination in Federated Learning](https://www.researchgate.net/profile/Ximeng-Liu-5/publication/340134612_Learn_to_Forget_User-Level_Memorization_Elimination_in_Federated_Learning/links/5e849e64a6fdcca789e5f955/Learn-to-Forget-User-Level-Memorization-Elimination-in-Federated-Learning.pdf). In arXiv 2020.

Sommer et al. [Towards Probabilistic Verification of Machine Unlearning](https://arxiv.org/abs/2003.04247). In arXiv 2020.

Yiu et al. [Learn to Forget: User-Level Memorization Elimination in Federated Learning](https://arxiv.org/abs/2003.10933). In arXiv 2020.

Yu et al. [Membership Inference with Privately Augmented Data Endorses the Benign while Suppresses the Adversary](https://arxiv.org/abs/2007.10567). In arXiv 2020.

## 2019

Chen et al. [A Novel Online Incremental and Decremental Learning Algorithm Based on Variable Support Vector Machine](https://link.springer.com/article/10.1007/s10586-018-1772-4). In Cluster Computing 2019.

Ginart et al. [Making AI Forget You: Data Deletion in Machine Learning](http://papers.nips.cc/paper/8611-making-ai-forget-you-data-deletion-in-machine-learning). In NeurIPS 2019.

Schelter. [“Amnesia” – Towards Machine Learning Models That Can Forget User Data Very Fast](http://cidrdb.org/cidr2020/papers/p32-schelter-cidr20.pdf). In AIDB 2019.

Shintre et al. [Making Machine Learning Forget](https://link.springer.com/chapter/10.1007/978-3-030-21752-5_6). In APF 2019.

Du et al. [Lifelong Anomaly Detection Through Unlearning](https://dl.acm.org/doi/abs/10.1145/3319535.3363226). In CCS 2019.

Wang et al. [Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks](https://people.cs.vt.edu/vbimal/publications/backdoor-sp19.pdf). In IEEE Symposium on Security and Privacy 2019.

Tople te al. [Analyzing Privacy Loss in Updates of Natural Language Models](https://arxiv.org/abs/1912.07942). In arXiv 2019.

## 2018

Cao et al. [Efficient Repair of Polluted Machine Learning Systems via Causal Unlearning](https://dl.acm.org/citation.cfm?id=3196517). In ASIACCS 2018.

European Union. [GDPR](https://gdpr.eu/), 2018.

State of California. [California Consumer Privacy Act](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375), 2018.

Veale et al. [Algorithms that remember: model inversion attacks and data protection law](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2018.0083). In The Royal Society 2018.

Villaronga et al. [Humans Forget, Machines Remember: Artificial Intelligence and the Right to Be Forgotten](https://www.sciencedirect.com/science/article/pii/S0267364917302091). In Computer Law & Security Review 2018.

## 2017

Kwak et al. [Let Machines Unlearn--Machine Unlearning and the Right to be Forgotten](https://aisel.aisnet.org/amcis2017/InformationSystems/Presentations/14/). In SIGSEC 2017.

Shokri et al. [Membership Inference Attacks Against Machine Learning Models](https://ieeexplore.ieee.org/abstract/document/7958568). In SP 2017.

## Before 2017

Cao and Yang. [Towards Making Systems Forget with Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/7163042). In IEEE Symposium on Security and Privacy 2015.

Tsai et al. [Incremental and decremental training for linear classification](https://dl.acm.org/citation.cfm?id=2623661). In KDD 2014.

Karasuyama and Takeuchi. [Multiple Incremental Decremental Learning of Support Vector Machines](https://ieeexplore.ieee.org/abstract/document/5484614). In NeurIPS 2009.

Duan et al. [Decremental Learning Algorithms for Nonlinear Langrangian and Least Squares Support Vector Machines](https://pdfs.semanticscholar.org/312c/677f0882d0dfd60bfd77346588f52aefd10f.pdf). In OSB 2007.

Romero et al. [Incremental and Decremental Learning for Linear Support Vector Machines](https://link.springer.com/chapter/10.1007/978-3-540-74690-4_22). In ICANN 2007.

Tveit et al. [Incremental and Decremental Proximal Support Vector Classification using Decay Coefficients](https://link.springer.com/chapter/10.1007/978-3-540-45228-7_42). In DaWaK 2003.

Tveit and Hetland. [Multicategory Incremental Proximal Support Vector Classifiers](https://link.springer.com/chapter/10.1007/978-3-540-45224-9_54). In KES 2003.

Cauwenberghs and Poggio. [Incremental and Decremental Support Vector Machine Learning](http://papers.nips.cc/paper/1814-incremental-and-decremental-support-vector-machine-learning.pdf). In NeurIPS 2001.

Canada. [PIPEDA](https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/), 2000.
