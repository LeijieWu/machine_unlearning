# Machine Unlearning Papers

## 2022

Chen et al. [Recommendation Unlearning](https://arxiv.org/abs/2201.06820). In TheWebConf 2022.

Fu et al. [Knowledge Removal in Sampling-based Bayesian Inference](https://openreview.net/forum?id=dTqOcTUOQO). In ICLR 2022.

Liu et al. [Backdoor Defense with Machine Unlearning](https://arxiv.org/abs/2201.09538). In INFOCOM 2022.

Marchant et al. [Hard to Forget: Poisoning Attacks on Certified Machine Unlearning](https://arxiv.org/abs/2109.08266). In AAAI 2021.

Wang et al. [Federated Unlearning via Class-Discriminative Pruning](https://arxiv.org/abs/2110.11794). In WWW 2022.

### arXiv

Chundawat et al. [Zero-Shot Machine Unlearning](https://arxiv.org/pdf/2201.05629.pdf). In arXiv 2022.

Goal et al. [Evaluating Inexact Unlearning Requires Revisiting Forgetting](https://arxiv.org/abs/2201.06640). In arXiv 2022.

Tarun et al. [Fast Yet Effective Machine Unlearning](https://arxiv.org/abs/2111.08947). In arXiv 2022.

Wu et al. [Federated Unlearning with Knowledge Distillation](https://arxiv.org/abs/2201.09441). In. arXiv 2022.

## 2021

Aldaghri et al. [Coded Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/9458237). In IEEE Access 2021.

Brophy and Lowd. [Machine Unlearning for Random Forests](https://arxiv.org/abs/2009.05567). In ICML 2021.

Bourtoule et al. [Machine Unlearning](https://arxiv.org/abs/1912.03817). In IEEE Symposium on Security and Privacy 2021.

Chen et al. [When Machine Unlearning Jeopardizes Privacy](https://arxiv.org/abs/2005.02205). In CCS 2021.

Dang et al. [Right to Be Forgotten in the Age of Machine Learning](https://link.springer.com/chapter/10.1007/978-3-030-71782-7_35). In ICADS 2021.

Golatkar et al. [Mixed-Privacy Forgetting in Deep Networks](https://arxiv.org/abs/2012.13431). In CVPR 2021.

Goyal et al. [Revisiting Machine Learning Training Process for Enhanced Data Privacy](https://dl.acm.org/doi/10.1145/3474124.3474208). In IC3 2021.

Graves et al. [Amnesiac Machine Learning](https://ojs.aaai.org/index.php/AAAI/article/view/17371). In AAAI 2021.

Gupta et al. [Adaptive Machine Unlearning](https://arxiv.org/pdf/2106.04378.pdf). In Neurips 2021.

Huang et al. [Unlearnable Examples: Making Personal Data Unexploitable](https://arxiv.org/abs/2101.04898). In ICLR 2021.

Huang et al. [EMA: Auditing Data Removal from Trained Models](https://link.springer.com/chapter/10.1007/978-3-030-87240-3_76). In MICCAI 2021.

Khan and Swaroop. [Knowledge-Adaptation Priors](https://proceedings.neurips.cc/paper/2021/hash/a4380923dd651c195b1631af7c829187-Abstract.html). In NeurIPS 2021.

Liu et al. [FedEraser: Enabling Efficient Client-Level Data Removal from Federated Learning Models](https://ieeexplore.ieee.org/abstract/document/9521274). In IWQoS 2021.

Liu et al. [RevFRF: Enabling Cross-domain Random Forest Training with Revocable Federated Learning](https://ieeexplore.ieee.org/abstract/document/9514457). In IEEE Transactions on Secure and Depndable Computing 2021.

Neel et al. [Descent-to-Delete:
Gradient-Based Methods for Machine Unlearning](http://proceedings.mlr.press/v132/neel21a.html). In ALT 2021.

Schelter et al. [HedgeCut: Maintaining Randomised Trees for Low-Latency Machine Unlearning](https://ssc.io/pdf/rdm235.pdf). In SIGMOD 2021.

Sekhari et al. [Remember What You Want to Forget: Algorithms for Machine Unlearning](https://arxiv.org/abs/2103.03279). In Neurips 2021.

Shibata et al. [Learning with Selective Forgetting](https://www.ijcai.org/proceedings/2021/0137.pdf). In IJCAI 2021.

Jose and Simeone [A Unified PAC-Bayesian Framework for Machine Unlearning via Information Risk Minimization](https://ieeexplore.ieee.org/abstract/document/9596170). In MLSP Workshop 2021.

Tahiliani et al. [Machine Unlearning: Its Need and Implementation Strategies](https://dl.acm.org/doi/abs/10.1145/3474124.3474158). In IC3 2021.

Ullah et al. [Machine Unlearning via Algorithmic Stability](http://proceedings.mlr.press/v134/ullah21a.html). In COLT 2021.

Wang and Schelter [Efficiently Maintaining Next Basket Recommendations under Additions and Deletions of Baskets and Items](https://arxiv.org/abs/2201.13313). In ORSUM Workshop 2021.

### arXiv

Chen et al. [Graph Unlearning](https://arxiv.org/abs/2103.14991). In arXiv 2021.

Chen et al. [Machine unlearning via GAN](https://arxiv.org/abs/2111.11869). In arXiv 2021.

Fu et al. [Bayesian Inference Forgetting](https://arxiv.org/abs/2101.06417). In arXiv 2021.

He et al. [DeepObliviate: A Powerful Charm for Erasing Data Residual Memory in Deep Neural Networks](https://arxiv.org/abs/2105.06209). In arXiv 2021.

Madahaven and Mathioudakis. [Certifiable Machine Unlearning for Linear Models](https://arxiv.org/abs/2106.15093). In arXiv 2021.

Parne et al. [Machine Unlearning: Learning, Polluting, and Unlearning for Spam Email](https://arxiv.org/abs/2111.14609). In arXiv 2021.

Peste et al. [SSSE: Efficiently Erasing Samples from Trained Machine Learning Models](https://arxiv.org/abs/2107.03860). In arXiv 2021.

Tarun et al. [Fast Yet Effective Machine Unlearning](https://arxiv.org/abs/2111.08947). In arXiv 2021.

Thudi et al. [Unrolling SGD: Understanding Factors Influencing Machine Unlearning](https://arxiv.org/abs/2109.13398). In arXiv 2021.

Thudi et al. [On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning](https://arxiv.org/abs/2110.11891). In arXiv 2021.

Thudi et al. [Bounding Membership Inference ](https://openreview.net/forum?id=Mh40mAxxAUz). In arXiv 2021.

Wang et al. [Federated Unlearning via Class-Discriminative Pruning](https://arxiv.org/abs/2110.11794). In arXiv 2021.

Warnecke et al. [Machine Unlearning for Features and Labels](https://arxiv.org/pdf/2108.11577.pdf). In arXiv 2021.

Zeng et al. [Learning to Refit for Convex Learning Problems](https://arxiv.org/abs/2111.12545) In arXiv 2021.

## 2020

Garg et al. [Formalizing Data Deletion in the Context of the Right to be Forgotten](https://arxiv.org/abs/2002.10635). In EUROCRYPT 2020.

Golatkar et al. [Forgetting Outside the Box: Scrubbing Deep Networks of Information Accessible from Input-Output Observations](https://arxiv.org/abs/1911.04933). In ECCV 2020.

Guo et al. [Certified Data Removal from Machine Learning Models](https://arxiv.org/abs/1911.03030). In ICML 2020.

Golatkar et al. [Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks](https://arxiv.org/abs/1911.04933). In CVPR 2020.

Nguyen et al. [Variational Bayesian Unlearning](https://proceedings.neurips.cc/paper/2020/hash/b8a6550662b363eb34145965d64d0cfb-Abstract.html). In NeurIPS 2020.

Tople te al. [Analyzing Information Leakage of Updates to Natural Language Models](https://dl.acm.org/doi/abs/10.1145/3372297.3417880). In CCS 2020.

Wu et. al [DeltaGrad: Rapid Retraining of Machine Learning Models](https://icml.cc/virtual/2020/poster/5915). In ICML 2020.

### arXiv

Baumhauer et al. [Machine Unlearning: Linear Filtration for Logit-based Classifiers](https://arxiv.org/abs/2002.02730). In arXiv 2020.

Felps et al. [Class Clown: Data Redaction in Machine Unlearning at Enterprise Scale](https://arxiv.org/abs/2012.04699). In arXiv 2020.

Izzo et al. [Approximate Data Deletion from Machine Learning Models: Algorithms and Evaluations](https://arxiv.org/abs/2002.10077). In arXiv 2020.

Li et al. [Online Forgetting Process for Linear Regression Models](https://arxiv.org/abs/2012.01668). In arXiv 2020.

Liu et al. [Learn to Forget: User-Level Memorization
Elimination in Federated Learning](https://www.researchgate.net/profile/Ximeng-Liu-5/publication/340134612_Learn_to_Forget_User-Level_Memorization_Elimination_in_Federated_Learning/links/5e849e64a6fdcca789e5f955/Learn-to-Forget-User-Level-Memorization-Elimination-in-Federated-Learning.pdf). In arXiv 2020.

Sommer et al. [Towards Probabilistic Verification of Machine Unlearning](https://arxiv.org/abs/2003.04247). In arXiv 2020.

Yu et al. [Membership Inference with Privately Augmented Data Endorses the Benign while Suppresses the Adversary](https://arxiv.org/abs/2007.10567). In arXiv 2020.

## 2019

Chen et al. [A Novel Online Incremental and Decremental Learning Algorithm Based on Variable Support Vector Machine](https://link.springer.com/article/10.1007/s10586-018-1772-4). In Cluster Computing 2019.

Ginart et al. [Making AI Forget You: Data Deletion in Machine Learning](http://papers.nips.cc/paper/8611-making-ai-forget-you-data-deletion-in-machine-learning). In NeurIPS 2019.

Schelter. [“Amnesia” – Towards Machine Learning Models That Can Forget User Data Very Fast](http://cidrdb.org/cidr2020/papers/p32-schelter-cidr20.pdf). In AIDB 2019.

Shintre et al. [Making Machine Learning Forget](https://link.springer.com/chapter/10.1007/978-3-030-21752-5_6). In APF 2019.

Du et al. [Lifelong Anomaly Detection Through Unlearning](https://dl.acm.org/doi/abs/10.1145/3319535.3363226). In CCS 2019.

Wang et al. [Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks](https://people.cs.vt.edu/vbimal/publications/backdoor-sp19.pdf). In IEEE Symposium on Security and Privacy 2019.

## 2018

Cao et al. [Efficient Repair of Polluted Machine Learning Systems via Causal Unlearning](https://dl.acm.org/citation.cfm?id=3196517). In ASIACCS 2018.

European Union. [GDPR](https://gdpr.eu/), 2018.

State of California. [California Consumer Privacy Act](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375), 2018.

Veale et al. [Algorithms that remember: model inversion attacks and data protection law](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2018.0083). In The Royal Society 2018.

Villaronga et al. [Humans Forget, Machines Remember: Artificial Intelligence and the Right to Be Forgotten](https://www.sciencedirect.com/science/article/pii/S0267364917302091). In Computer Law & Security Review 2018.

## 2017

Kwak et al. [Let Machines Unlearn--Machine Unlearning and the Right to be Forgotten](https://aisel.aisnet.org/amcis2017/InformationSystems/Presentations/14/). In SIGSEC 2017.

Shokri et al. [Membership Inference Attacks Against Machine Learning Models](https://ieeexplore.ieee.org/abstract/document/7958568). In SP 2017.

## Before 2017

Cao and Yang. [Towards Making Systems Forget with Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/7163042). In IEEE Symposium on Security and Privacy 2015.

Tsai et al. [Incremental and decremental training for linear classification](https://dl.acm.org/citation.cfm?id=2623661). In KDD 2014.

Karasuyama and Takeuchi. [Multiple Incremental Decremental Learning of Support Vector Machines](https://ieeexplore.ieee.org/abstract/document/5484614). In NeurIPS 2009.

Duan et al. [Decremental Learning Algorithms for Nonlinear Langrangian and Least Squares Support Vector Machines](https://pdfs.semanticscholar.org/312c/677f0882d0dfd60bfd77346588f52aefd10f.pdf). In OSB 2007.

Romero et al. [Incremental and Decremental Learning for Linear Support Vector Machines](https://link.springer.com/chapter/10.1007/978-3-540-74690-4_22). In ICANN 2007.

Tveit et al. [Incremental and Decremental Proximal Support Vector Classification using Decay Coefficients](https://link.springer.com/chapter/10.1007/978-3-540-45228-7_42). In DaWaK 2003.

Tveit and Hetland. [Multicategory Incremental Proximal Support Vector Classifiers](https://link.springer.com/chapter/10.1007/978-3-540-45224-9_54). In KES 2003.

Cauwenberghs and Poggio. [Incremental and Decremental Support Vector Machine Learning](http://papers.nips.cc/paper/1814-incremental-and-decremental-support-vector-machine-learning.pdf). In NeurIPS 2001.

Canada. [PIPEDA](https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/), 2000.
