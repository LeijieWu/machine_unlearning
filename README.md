# Notes on Machine Unlearning

## Problem Formulation

### Legal

Garg et al. [Formalizing Data Deletion in the Context of the Right to be Forgotten](https://arxiv.org/abs/2002.10635). In arXiv 2020.

Shintre et al. [Making Machine Learning Forget](https://link.springer.com/chapter/10.1007/978-3-030-21752-5_6). In APF 2019.

European Union. [GDPR](https://gdpr.eu/), 2018.

State of California. [California Consumer Privacy Act](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375), 2018.

Villaronga et al. [Humans Forget, Machines Remember: Artificial Intelligence and the Right to Be Forgotten](https://www.sciencedirect.com/science/article/pii/S0267364917302091). In Computer Law & Security Review 2018.

Kwak et al. [Let Machines Unlearn--Machine Unlearning and the Right to be Forgotten](https://aisel.aisnet.org/amcis2017/InformationSystems/Presentations/14/). In SIGSEC 2017.

Canada. [PIPEDA](https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/), 2000.

### Membership Inference Attacks

Yu et al. [Membership Inference with Privately Augmented Data Endorses the Benign while Suppresses the Adversary](https://arxiv.org/abs/2007.10567). In arXiv 2020.

Veale et al. [Algorithms that remember: model inversion attacks and data protection law](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2018.0083). In The Royal Society 2018.

Shokri et al. [Membership Inference Attacks Against Machine Learning Models](https://ieeexplore.ieee.org/abstract/document/7958568). In SP 2017.

## Exact Unlearning

Bourtoule et al. [Machine Unlearning](https://arxiv.org/abs/1912.03817). In IEEE Symposium on Security and Privacy 2021.

Aldaghri et al. [Coded Machine Unlearning](https://arxiv.org/abs/2012.15721). In arXiv 2020.

Brophy and Lowd. [DART: Data Addition and Removal Trees](https://arxiv.org/abs/2009.05567). In arXiv 2020.

Ginart et al. [Making AI Forget You: Data Deletion in Machine Learning](http://papers.nips.cc/paper/8611-making-ai-forget-you-data-deletion-in-machine-learning). In NeurIPS 2019.

Chen et al. [A Novel Online Incremental and Decremental Learning Algorithm Based on Variable Support Vector Machine](https://link.springer.com/article/10.1007/s10586-018-1772-4). In Cluster Computing 2019.

Schelter. [“Amnesia” – Towards Machine Learning Models That Can Forget User Data Very Fast](http://cidrdb.org/cidr2020/papers/p32-schelter-cidr20.pdf). In AIDB 2019.

Cao et al. [Efficient Repair of Polluted Machine Learning Systems via Causal Unlearning](https://dl.acm.org/citation.cfm?id=3196517). In ASIACCS 2018.

Cao and Yang. [Towards Making Systems Forget with Machine Unlearning](https://ieeexplore.ieee.org/abstract/document/7163042). In IEEE Symposium on Security and Privacy 2015.

Karasuyama and Takeuchi. [Multiple Incremental Decremental Learning of Support Vector Machines](https://ieeexplore.ieee.org/abstract/document/5484614). In NeurIPS 2009.

Duan et al. [Decremental Learning Algorithms for Nonlinear Langrangian and Least Squares Support Vector Machines](https://pdfs.semanticscholar.org/312c/677f0882d0dfd60bfd77346588f52aefd10f.pdf). In OSB 2007.

Romero et al. [Incremental and Decremental Learning for Linear Support Vector Machines](https://link.springer.com/chapter/10.1007/978-3-540-74690-4_22). In ICANN 2007.

Tveit et al. [Incremental and Decremental Proximal Support Vector Classification using Decay Coefficients](https://link.springer.com/chapter/10.1007/978-3-540-45228-7_42). In DaWaK 2003.

Tveit and Hetland. [Multicategory Incremental Proximal Support Vector Classifiers](https://link.springer.com/chapter/10.1007/978-3-540-45224-9_54). In KES 2003.

Cauwenberghs and Poggio. [Incremental and Decremental Support Vector Machine Learning](http://papers.nips.cc/paper/1814-incremental-and-decremental-support-vector-machine-learning.pdf). In NeurIPS 2001.

## Approximate Unlearning

Fu et al. [Bayesian Inference Forgetting](https://arxiv.org/abs/2101.06417). in arXiv 2021.

Guo et al. [Certified Data Removal from Machine Learning Models](https://arxiv.org/abs/1911.03030). In ICML 2020.

Wu et. al [DeltaGrad: Rapid Retraining of Machine Learning Models](https://icml.cc/virtual/2020/poster/5915). In ICML 2020.

Izzo et al. [Approximate Data Deletion from Machine Learning Models: Algorithms and Evaluations](https://arxiv.org/abs/2002.10077). In arXiv 2020.

Yiu et al. [Learn to Forget: User-Level Memorization Elimination in Federated Learning](https://arxiv.org/abs/2003.10933). In arXiv 2020.

Golatkar et al. [Mixed-Privacy Forgetting in Deep Networks](https://arxiv.org/abs/2012.13431). In arXiv 2020.

Golatkar et al. [Forgetting Outside the Box: Scrubbing Deep Networks of Information Accessible from Input-Output Observations](https://arxiv.org/abs/1911.04933). In arXiv 2020.

Golatkar et al. [Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks](https://arxiv.org/abs/1911.04933). In CVPR 2020.

Baumhauer et al. [Machine Unlearning: Linear Filtration for Logit-based Classifiers](https://arxiv.org/abs/2002.02730). In arXiv 2020.

Tsai et al. [Incremental and decremental training for linear classification](https://dl.acm.org/citation.cfm?id=2623661). In KDD 2014.

## Mitigation

Tople te al. [Analyzing Privacy Loss in Updates of Natural Language Models](https://arxiv.org/abs/1912.07942). In arXiv 2019.

Du et al. [Lifelong Anomaly Detection Through Unlearning](https://dl.acm.org/doi/abs/10.1145/3319535.3363226). In CCS 2019.

Wang et al. [Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks](https://people.cs.vt.edu/vbimal/publications/backdoor-sp19.pdf). In IEEE Symposium on Security and Privacy 2019.

## Deletion Verification

Chen et al. [When Machine Unlearning Jeopardizes Privacy](https://arxiv.org/abs/2005.02205). In arXiv 2020.

Sommer et al. [Towards Probabilistic Verification of Machine Unlearning](https://arxiv.org/abs/2003.04247). In arXiv 2020.